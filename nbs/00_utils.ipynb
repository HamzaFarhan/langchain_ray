{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "from dreamai.imports import *\n",
    "from langchain_ray.imports import *\n",
    "from langchain_ray.remote_utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def is_doc(x):\n",
    "    return isinstance(x, Document)\n",
    "\n",
    "\n",
    "def list_or_array(x):\n",
    "    return is_list(x) or is_array(x)\n",
    "\n",
    "\n",
    "def nested_list(x):\n",
    "    is_nested = list_or_array(x) and list_or_array(x[0])\n",
    "    if not list_or_array(x):\n",
    "        x = [x]\n",
    "    if not list_or_array(x[0]):\n",
    "        x = [x]\n",
    "    return x, is_nested\n",
    "\n",
    "\n",
    "def unnest_list(x):\n",
    "    if is_list(x) and is_list(x[0]) and len(x) == 1:\n",
    "        x = x[0]\n",
    "    return x\n",
    "\n",
    "\n",
    "def cid_to_char(cidx: str):\n",
    "    try:\n",
    "        return chr(int(re.findall(r\"\\(cid\\:(\\d+)\\)\", cidx)[0]) + 29)\n",
    "    except:\n",
    "        return cidx\n",
    "\n",
    "\n",
    "def process_text(text: str):\n",
    "    text = text.strip()\n",
    "    text = demoji.replace(text, \"\")\n",
    "    text = clean(\n",
    "        text,\n",
    "        # no_urls=True,\n",
    "        no_emails=True,\n",
    "        no_phone_numbers=True,\n",
    "        no_currency_symbols=True,\n",
    "        # replace_with_url=\"\",\n",
    "        replace_with_email=\"\",\n",
    "        replace_with_phone_number=\"\",\n",
    "        replace_with_currency_symbol=\"\",\n",
    "    )\n",
    "    text = cid_to_char(text)\n",
    "    text = re.sub(\"\\xa0\", \" \", text)\n",
    "    text = re.sub(r\"\\uf0b7\", \" \", text)\n",
    "    text = re.sub(r\"\\(cid:\\d{0,3}\\)\", \" \", text)\n",
    "    text = re.sub(r\"•\", \"\", text)\n",
    "    text = re.sub(r\"●\", \"\", text)\n",
    "    text = re.sub(r\"▪\", \"\", text)\n",
    "    text = re.sub(r\"\", \"\", text)\n",
    "    text = re.sub(r\"➢\", \"\", text)\n",
    "    text = re.sub(r\"\\u2b9a\", \"\", text)\n",
    "    text = re.sub(r\"\\u201c\", \"\", text)\n",
    "    text = re.sub(r\"\\u201d\", \"\", text)\n",
    "    text = re.sub(r\"\\u2013\", \" \", text)\n",
    "    text = re.sub(r\"\\u2019\", \"'\", text)\n",
    "    text = re.sub(r\"\\u2018\", \"'\", text)\n",
    "    text = re.sub(r\"\\u00f4\", \" \", text)\n",
    "    text = re.sub(r\"\\u00f6\", \"o\", text)\n",
    "    text = re.sub(r\"\\u00e9\", \"e\", text)\n",
    "    text = re.sub(r\"\\u00e8\", \"e\", text)\n",
    "    text = re.sub(r\"\\u00e7\", \" \", text)\n",
    "    text = re.sub(r\"\\u00a7\", \"\", text)\n",
    "    text = re.sub(r\"\\u00e3\", \"a\", text)\n",
    "    text = re.sub(r\"\\uf0a7\", \"\", text)\n",
    "    text = re.sub(r\"\\uf076\", \"\", text)\n",
    "    text = re.sub(r\"\\u00ad\", \"\", text)\n",
    "    text = re.sub(r\"\\u00ab\", \"\", text)\n",
    "    text = re.sub(r\"\\u00bb\", \"\", text)\n",
    "    text = re.sub(r\"\\uf02d\", \"\", text)\n",
    "    text = re.sub(r\"\\uf0fc\", \"\", text)\n",
    "    text = re.sub(r\"\\uf06e\", \"\", text)\n",
    "    text = re.sub(r\"\\uf07a\", \"\", text)\n",
    "    text = re.sub(r\"\\ufb01\", \"fi\", text)\n",
    "    text = re.sub(r\"\\ufb00\", \"ff\", text)\n",
    "    text = re.sub(r\"\\uf0d8\", \"\", text)\n",
    "    text = re.sub(r\"\\u00b7\", \"\", text)\n",
    "    text = re.sub(\"\\t\", \" \", text)\n",
    "    text = re.sub(\" +\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def proc_doc_text(doc):\n",
    "    doc.page_content = process_text(doc.page_content)\n",
    "    return doc\n",
    "\n",
    "\n",
    "def bold_text(text):\n",
    "    return \"\\033[1m\" + text + \"\\033[0m\"\n",
    "\n",
    "\n",
    "def print_doc(doc):\n",
    "    print(f\"{bold_text('Page_Content:')} {doc.page_content}\\n\")\n",
    "    print(f\"{bold_text('Metadata:')} {doc.metadata}\\n\")\n",
    "\n",
    "\n",
    "def docs_to_json(\n",
    "    docs,\n",
    "    json_folder,\n",
    "    data={},\n",
    "    data_key=\"data\",\n",
    "    with_metadata=True,\n",
    "    with_content=False,\n",
    "    indent=None,\n",
    "):\n",
    "    if is_list(data):\n",
    "        data = {data_key: data}\n",
    "    json_folder, remote_folder = handle_input_path(json_folder)\n",
    "    os.makedirs(json_folder, exist_ok=True)\n",
    "    for i, doc in enumerate(flatten_list(docs)):\n",
    "        doc_dict = {}\n",
    "        if with_content:\n",
    "            doc_dict[\"page_content\"] = doc.page_content\n",
    "        if with_metadata:\n",
    "            doc_dict[\"metadata\"] = doc.metadata\n",
    "        for k, v in data.items():\n",
    "            if is_list(v) and len(v) == len(docs):\n",
    "                doc_dict[k] = v[i]\n",
    "        if len(doc_dict) == 0:\n",
    "            doc_dict = {\"page_content\": doc.page_content, \"metadata\": doc.metadata}\n",
    "        source = Path(doc.metadata[\"source\"])\n",
    "        json_path = (Path(json_folder) / source.stem).with_suffix(\".json\")\n",
    "        if json_path.exists():\n",
    "            json_path = find_alternate_path(json_path, first_idx=1, verbose=False)\n",
    "        with open(json_path, \"w\") as f:\n",
    "            json.dump(doc_dict, f, indent=indent)\n",
    "    if is_bucket(remote_folder):\n",
    "        bucket_up(json_folder, remote_folder)\n",
    "    return docs\n",
    "\n",
    "\n",
    "def add_docs_metadata(docs, fn=None, key=\"new_meta\"):\n",
    "    if fn is None:\n",
    "        return docs\n",
    "    docs, is_nested = nested_list(docs)\n",
    "    for docs_ in docs:\n",
    "        fn_res = fn(docs_)\n",
    "        for doc, res in zip(docs_, fn_res):\n",
    "            doc.metadata[key] = res\n",
    "    return docs if is_nested else docs[0]\n",
    "\n",
    "\n",
    "def add_str_to_docs(docs, str, key=\"new_meta\"):\n",
    "    fn = lambda x: [str] * len(x)\n",
    "    return add_docs_metadata(docs, fn=fn, key=key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
