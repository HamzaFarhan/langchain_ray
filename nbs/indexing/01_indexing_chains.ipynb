{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chains\n",
    "\n",
    "> Chains-based functions for Indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp indexing.chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "from langchain_ray.imports import *\n",
    "from langchain_ray.chains import *\n",
    "from langchain_ray.utils import *\n",
    "from langchain_ray.indexing.utils import *\n",
    "from langchain_ray.pdf.chains import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def docs_to_faiss_chain(\n",
    "    ems_model,\n",
    "    index_folder,\n",
    "    index_name,\n",
    "    input_variables=[\"docs\"],\n",
    "    output_variables=[\"docs\"],\n",
    "    verbose=False,\n",
    "):\n",
    "    \"Chain that takes a list of `Documents` and adds them to a `FAISS` index in `index_folder`.\"\n",
    "    return transform_chain(\n",
    "        docs_to_faiss,\n",
    "        input_variables=input_variables,\n",
    "        output_variables=output_variables,\n",
    "        transform_kwargs={\n",
    "            \"ems_model\": ems_model,\n",
    "            \"index_folder\": index_folder,\n",
    "            \"index_name\": index_name,\n",
    "        },\n",
    "        data_kwargs_mapping={input_variables[0]: \"docs\"},\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "\n",
    "def pdfs_to_faiss_chain(\n",
    "    ems_model,  # The model to use for vectorestore embeddings.\n",
    "    index_folder,  # The folder to store the FAISS index.\n",
    "    index_name,  # The name of the FAISS index.\n",
    "    input_variables=[\"pdf_path\"],\n",
    "    output_variables=[\"docs\"],\n",
    "    chunk_size=200,  # The number of characters per Document.\n",
    "    chunk_overlap=20,  # The number of characters to overlap between Documents.\n",
    "    docs_block_size=1500,  # The number of Documents to process in a single Ray task.\n",
    "    num_cpus=12,  # The number of CPUs to use for Ray.\n",
    "    num_gpus=1,  # The number of GPUs to use for Ray.\n",
    "    verbose=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Chain that adds PDFs to `FAISS` indexes in `index_folder`.\n",
    "    If there are more than `docs_block_size` extracted `Documents`, indexing will be distributed using `Ray`.\n",
    "    \"\"\"\n",
    "    docs_chain = pdfs_to_docs_chain(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        input_variables=input_variables,\n",
    "        output_variables=[\"dc\"],\n",
    "        verbose=verbose,\n",
    "    )\n",
    "    faiss_chain = docs_to_faiss_chain(\n",
    "        ems_model=ems_model,\n",
    "        index_folder=index_folder,\n",
    "        index_name=index_name,\n",
    "        input_variables=[\"dc\"],\n",
    "        output_variables=output_variables,\n",
    "        verbose=verbose,\n",
    "    )\n",
    "    faiss_chain = ray_chain(\n",
    "        faiss_chain,\n",
    "        block_size=docs_block_size,\n",
    "        num_cpus=num_cpus,\n",
    "        num_gpus=num_gpus,\n",
    "        verbose=verbose,\n",
    "    )\n",
    "    return SequentialChain(\n",
    "        chains=[docs_chain, faiss_chain],\n",
    "        input_variables=input_variables,\n",
    "        output_variables=output_variables,\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "\n",
    "def index_query_chain(\n",
    "    ems_model,  # The SentenceTransformer model to use for vectorestore embeddings.\n",
    "    index_folder,  # The folder with the FAISS indexes.\n",
    "    index_name,  # The name of the FAISS index.\n",
    "    input_variables=[\"query\", \"k\"],\n",
    "    output_variables=[\"search_results\"],\n",
    "    block_size=10,  # The number of indexes to process in a single Ray task.\n",
    "    num_cpus=12,  # The number of CPUs to use for Ray.\n",
    "    num_gpus=1,  # The number of GPUs to use for Ray.\n",
    "    verbose=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Chain that takes a `query` and returns the top `k` results from the `FAISS` indexes in `index_folder`.\n",
    "    If there are more than `block_size` indexes, search will be distributed using `Ray`.\n",
    "    \"\"\"\n",
    "\n",
    "    index_names_chain = transform_chain(\n",
    "        index_names,\n",
    "        transform_kwargs={\"index_folder\": index_folder, \"index_name\": index_name},\n",
    "        input_variables=[\"k\"],\n",
    "        output_variables=[\"index_names\"],\n",
    "    )\n",
    "\n",
    "    search_faiss_chain = transform_chain(\n",
    "        search_faiss,\n",
    "        transform_kwargs={\"index_folder\": index_folder, \"ems_model\": ems_model},\n",
    "        input_variables=[\"index_names\", \"query\", \"k\"],\n",
    "        output_variables=[\"res\"],\n",
    "    )\n",
    "\n",
    "    search_faiss_chain = ray_chain(\n",
    "        search_faiss_chain, block_size=block_size, num_cpus=num_cpus, num_gpus=num_gpus\n",
    "    )\n",
    "\n",
    "    def flatten_res(res, k):\n",
    "        if is_list(k):\n",
    "            k = k[0]\n",
    "        return [sorted(flatten_list(res), key=lambda x: x[1])[:k]]\n",
    "\n",
    "    res_chain = transform_chain(\n",
    "        flatten_res,\n",
    "        input_variables=[\"res\", \"k\"],\n",
    "        output_variables=output_variables,\n",
    "    )\n",
    "\n",
    "    return SequentialChain(\n",
    "        chains=[index_names_chain, search_faiss_chain, res_chain],\n",
    "        input_variables=input_variables,\n",
    "        output_variables=output_variables,\n",
    "        verbose=verbose,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
