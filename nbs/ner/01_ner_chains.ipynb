{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chains\n",
    "\n",
    "> Chains-based functions for NER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp ner.chains\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "from langchain_ray.imports import *\n",
    "from langchain_ray.chains import *\n",
    "from langchain_ray.utils import *\n",
    "from langchain_ray.pdf.utils import *\n",
    "from langchain_ray.pdf.chains import *\n",
    "from langchain_ray.ner.utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def add_ners_to_docs_chain(\n",
    "    e_ner,\n",
    "    j_ner,\n",
    "    input_variables=[\"docs\"],\n",
    "    output_variables=[\"ner_docs\"],\n",
    "    verbose=False,\n",
    "):\n",
    "    \"Chain that adds the NERs to a list of `Documents` usung `e_ner` and `j_ner`.\"\n",
    "    return transform_chain(\n",
    "        add_ners_to_docs,\n",
    "        transform_kwargs=dict(e_ner=e_ner, j_ner=j_ner),\n",
    "        input_variables=input_variables,\n",
    "        output_variables=output_variables,\n",
    "        vars_kwargs_mapping={input_variables[0]: \"docs\"},\n",
    "        verbose=verbose,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "\n",
    "device = default_device()\n",
    "verbose = True\n",
    "cats_model = SetFitModel.from_pretrained(\"HamzaFarhan/PDFSegs\").to(device)\n",
    "cats_folder = \"/media/hamza/data2/faiss_data/saved_cats\"\n",
    "if os.path.exists(cats_folder):\n",
    "    shutil.rmtree(cats_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "\n",
    "chain1 = pdf_to_docs_chain(\n",
    "    input_variables=[\"path\"], output_variables=[\"docs\"], verbose=verbose\n",
    ")\n",
    "chain2 = add_cats_to_docs_chain(\n",
    "    cats_model=cats_model,\n",
    "    input_variables=[\"docs\"],\n",
    "    output_variables=[\"cat_docs\"],\n",
    "    verbose=verbose,\n",
    ")\n",
    "chain3 = add_ners_to_docs_chain(\n",
    "    e_ner=load_edu_model(device=device),\n",
    "    j_ner=load_job_model(device=device),\n",
    "    input_variables=[\"cat_docs\"],\n",
    "    output_variables=[\"ner_docs\"],\n",
    "    verbose=verbose,\n",
    ")\n",
    "chain4 = docs_to_json_chain(\n",
    "    json_folder=cats_folder,\n",
    "    indent=4,\n",
    "    input_variables=[\"ner_docs\"],\n",
    "    output_variables=[\"json_docs\"],\n",
    "    verbose=verbose,\n",
    ")\n",
    "chain = SequentialChain(\n",
    "    chains=[chain1, chain2, chain3, chain4],\n",
    "    input_variables=[\"path\"],\n",
    "    output_variables=[\"json_docs\"],\n",
    "    verbose=verbose,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# | eval: false\n",
    "\n",
    "pdf = \"../../resumes_5/\"\n",
    "res = chain(dict(path=pdf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': '../../resumes_5/0cf20170-8051-41ba-9060-1a82d43f4289.pdf', 'page': 0, 'start_index': 3474, 'category': 'Education', 'ner': {'institute': 'university of mumbai', 'date': '2008 - 2011'}}\n",
      "bachelor of commerce (b. com) - university of mumbai 2008 - 2011\n"
     ]
    }
   ],
   "source": [
    "# | eval: false\n",
    "\n",
    "doc = res[\"json_docs\"][0][-1]\n",
    "print(doc.metadata)\n",
    "print(doc.page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
