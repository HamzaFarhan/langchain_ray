{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "from dreamai.core import *\n",
    "from dreamai.vision import *\n",
    "from dreamai.imports import *\n",
    "from langchain_ray.imports import *\n",
    "from langchain_ray.utils import *\n",
    "from langchain_ray.chains import *\n",
    "import pdfplumber\n",
    "from pypdf import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(\"/home/hamza/dev/HF/langchain_ray/resumes_5\").exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'docs': ['d1', 'd2', 'd3']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [\"docs\"]\n",
    "b = [[\"d1\", \"d2\", \"d3\"]]\n",
    "{k: v for k, v in zip(a, b)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty_row(row):\n",
    "    return len([c for c in row if c not in [\"\", None]]) == 0\n",
    "\n",
    "\n",
    "def full_row(row, cols):\n",
    "    return len([c for c in row if c not in [\"\", None]]) == len(cols)\n",
    "\n",
    "\n",
    "def is_empty(x):\n",
    "    return x in [\"\", None]\n",
    "\n",
    "\n",
    "def find_empty_id(table):\n",
    "    for i, row in enumerate(table):\n",
    "        if empty_row(row):\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "\n",
    "def page_to_order(\n",
    "    page,\n",
    "    table_settings={\n",
    "        \"horizontal_strategy\": \"text\",\n",
    "        \"vertical_strategy\": \"lines\",\n",
    "        \"intersection_x_tolerance\": 5,\n",
    "        \"snap_y_tolerance\": 5,\n",
    "    },\n",
    "):\n",
    "    table = page.extract_table(table_settings=table_settings)\n",
    "    cols_id = find_empty_id(table) + 1\n",
    "    cols = table[cols_id]\n",
    "    cols_dict = {c: [] for c in cols}\n",
    "    cols_id += 2\n",
    "    comments = []\n",
    "    for info_id, row in enumerate(table[cols_id:]):\n",
    "        if empty_row(row) or full_row(row, cols):\n",
    "            break\n",
    "        elif is_empty(row[0]) and not is_empty(row[1]):\n",
    "            comments.append(row[1])\n",
    "    info_id += cols_id\n",
    "    lines = []\n",
    "    for row in table[info_id:]:\n",
    "        if empty_row(row) and len(lines) > 0:\n",
    "            cols_dict[cols[1]].append(\", \".join(lines))\n",
    "            lines = []\n",
    "        else:\n",
    "            if not is_empty(row[0]):\n",
    "                cols_dict[cols[0]].append(row[0])\n",
    "            if not is_empty(row[1]):\n",
    "                lines.append(row[1])\n",
    "            for r, c in zip(row[2:], cols[2:]):\n",
    "                if not is_empty(r):\n",
    "                    cols_dict[c].append(r)\n",
    "    if len(lines) > 0:\n",
    "        cols_dict[cols[1]].append(\", \".join(lines))\n",
    "    cd0 = cols_dict[cols[0]]\n",
    "    cd_1 = cols_dict[cols[-1]]\n",
    "    cd_2 = cols_dict[cols[-2]]\n",
    "    if len(cd_1) > len(cd0) and len(cd_2) > len(cd0):\n",
    "        total = float(cd_1[-1].replace(\"$\", \"\").replace(\",\", \"\").strip())\n",
    "        cols_dict[cols[-1]] = cd_1[: len(cd0)]\n",
    "        cols_dict[cols[-2]] = cd_2[: len(cd0)]\n",
    "    else:\n",
    "        total = 0\n",
    "    return pd.DataFrame(cols_dict), \", \".join(comments), total\n",
    "\n",
    "\n",
    "def pdf_to_order(pdf):\n",
    "    pdf = pdfplumber.open(pdf)\n",
    "    dfs = []\n",
    "    comments_ = []\n",
    "    totals = []\n",
    "    for page in pdf.pages:\n",
    "        df, comments, total = page_to_order(page)\n",
    "        dfs.append(df)\n",
    "        comments_.append(comments)\n",
    "        totals.append(total)\n",
    "    order = pd.concat(dfs).reset_index(drop=True)\n",
    "    comments = comments_[0]\n",
    "    total = totals[-1]\n",
    "    return order, comments, total\n",
    "\n",
    "\n",
    "def page_to_extra_info(page):\n",
    "    text = page.extract_text().splitlines()\n",
    "    ik2 = [\"Purchase Order No.\", \"Incoterms\", \"Payment Terms\", \"Method of Shipping\"]\n",
    "    ik3 = [\"Target Ship Date\", \"Ship To\", \"Currency\"]\n",
    "    info_dict = {}\n",
    "    for k2 in ik2:\n",
    "        for t in text:\n",
    "            if t.startswith(k2):\n",
    "                t = t.replace(k2, \"\").strip()\n",
    "                for k3 in ik3:\n",
    "                    idx = t.find(k3)\n",
    "                    if idx != -1:\n",
    "                        info_dict[k2] = t[:idx]\n",
    "                        info_dict[k3] = t[idx:].replace(k3, \"\").replace(\":\", \"\").strip()\n",
    "                        break\n",
    "                    else:\n",
    "                        info_dict[k2] = t\n",
    "                break\n",
    "    return info_dict\n",
    "\n",
    "\n",
    "def pdf_to_info(pdf):\n",
    "    page = pdfplumber.open(pdf).pages[0]\n",
    "    tables = page.extract_tables()\n",
    "    info_table = tables[0][1][0].split(\"\\n\")\n",
    "    address_table = tables[1][1][0].split(\"\\n\")\n",
    "    info_keys = [\n",
    "        \"Order Number\",\n",
    "        \"Revision\",\n",
    "        \"Document Date\",\n",
    "        \"Customer No.\",\n",
    "        \"Quotation\",\n",
    "        \"Questions/Contact\",\n",
    "        \"Email\",\n",
    "        \"Requested by\",\n",
    "    ]\n",
    "    info_dict = {k: t.replace(k, \"\").strip() for k, t in zip(info_keys, info_table)}\n",
    "    address_dict = {\n",
    "        \"Address\": \", \".join(address_table[:-2]),\n",
    "        \"Tel\": address_table[-2].replace(\"Tel#\", \"\").strip(),\n",
    "        \"Fax\": address_table[-1].replace(\"Fax#\", \"\").strip(),\n",
    "    }\n",
    "    info_dict.update(address_dict)\n",
    "    extra_info = page_to_extra_info(page)\n",
    "    info_dict.update(extra_info)\n",
    "    info_dict = {k: [v] for k, v in info_dict.items()}\n",
    "    return pd.DataFrame(info_dict)\n",
    "\n",
    "\n",
    "def pdf_to_dfs(pdf):\n",
    "    info_dfs = []\n",
    "    order_dfs = []\n",
    "    for pdf in resolve_data_path(pdf):\n",
    "        if Path(pdf).suffix == \".pdf\":\n",
    "            order_info = pdf_to_info(pdf)\n",
    "            order, comments, total = pdf_to_order(pdf)\n",
    "            order_info = pdf_to_info(pdf)\n",
    "            order[\"Order Number\"] = order_info[\"Order Number\"][0]\n",
    "            order_info[\"Comments\"] = comments\n",
    "            order_info[\"Total\"] = total\n",
    "            info_dfs.append(pd.DataFrame(order_info))\n",
    "            order_dfs.append(\n",
    "                pd.DataFrame(order, columns=[\"Order Number\"] + list(order.keys())[:-1])\n",
    "            )\n",
    "    info_df = pd.concat(info_dfs).reset_index(drop=True)\n",
    "    order_df = pd.concat(order_dfs).reset_index(drop=True)\n",
    "    return info_df, order_df\n",
    "\n",
    "\n",
    "def load_csv(path):\n",
    "    loader = CSVLoader(file_path=path)\n",
    "    return loader.load()\n",
    "\n",
    "\n",
    "def load_csv_chain(input_variables=[\"csv\"], output_variables=[\"csv_data\"], verbose=False):\n",
    "    return transform_chain(\n",
    "        load_csv,\n",
    "        vars_kwargs_mapping={input_variables[0]: \"path\"},\n",
    "        input_variables=input_variables,\n",
    "        output_variables=output_variables,\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "\n",
    "def pdf_to_dfs_chain(\n",
    "    input_variables=[\"pdf\"], output_variables=[\"info_df\", \"order_df\"], verbose=False\n",
    "):\n",
    "    return transform_chain(\n",
    "        pdf_to_dfs,\n",
    "        vars_kwargs_mapping={input_variables[0]: \"pdf\"},\n",
    "        input_variables=input_variables,\n",
    "        output_variables=output_variables,\n",
    "        verbose=verbose,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfs = [\"/media/hamza/data2/wt1.pdf\"]\n",
    "pdf_chain = pdf_to_dfs_chain(\n",
    "    input_variables=[\"pdf\"], output_variables=[\"info_df\", \"order_df\"], verbose=False\n",
    ")\n",
    "pdf_dfs = pdf_chain(dict(pdf=pdfs))\n",
    "info_df = pdf_dfs[\"info_df\"]\n",
    "order_df = pdf_dfs[\"order_df\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/media/hamza/data2/wt1_info.json', 'w') as f:\n",
    "    json.dump(info_df.to_dict('records'), f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/media/hamza/data2/wt1_order.json', 'w') as f:\n",
    "    json.dump(order_df.to_dict('records'), f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFacePipeline(\n",
    "    pipeline=pipeline(\n",
    "        \"text2text-generation\",\n",
    "        model=\"google/flan-t5-large\",\n",
    "        device_map=default_device(),\n",
    "        max_new_tokens=256,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_chain = load_csv_chain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qty_temp = \"\"\"This is the context: {csv_data}\n",
    "What was the quantity of {input}?\n",
    "\"\"\"\n",
    "\n",
    "qty_prompt = PromptTemplate.from_template(qty_temp)\n",
    "llm_chain = LLMChain(prompt=qty_prompt, llm=llm)\n",
    "qty_chain = SequentialChain(chains=[csv_chain, llm_chain], input_variables=[\"csv\", \"input\"])\n",
    "\n",
    "input = \"25781\"\n",
    "qty_chain.run(csv=df_path, input=input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chains",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
